\section{Repeated Measures ANOVA}
\begin{frame}\frametitle{Repeated Measures ANOVA (rma)}
  \begin{itemize}
  \item equivalent of the one-way ANOVA, but for related, not independent groups,  \item in that sense it is the extension of the dependent t-test: he same people are being measured more than once on the same dependent variable
  \item here we will look at the simplest design of rma
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{Statistical Model}
  \begin{itemize}
  \item remember in basic one-way Anova $$Y_{ij} = \mu + \alpha_j + Error_{ij}$$
  \item error was assumed to have variance of $\sigma^2_{error}$
  \item measurements and therefore the errors were independed
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{Statistical Model}
  \begin{itemize}
  \item in repeated measurement Anova $$Y_{ij} = \mu + time_j + S_j + (time\times S)_{ij} + Error_{ij}$$
  \item assumes still that errors have the same variances and
  \item covariances are the same
  \end{itemize}
\end{frame}



\begin{frame}\frametitle{Repeated Measures ANOVA (rma)}
  \begin{itemize}
  \item main hypothesis of rma: $$\mu_1=\mu_2=\ldots =\mu_n$$
  \item here we will look at the simplest design of rma
  \item in this design the within group variance from above is splitted in variance caused by subject variability and the error variance
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{Repeated Measures ANOVA (rma)}
So we have one more sum of sqares:
  \begin{itemize}
  \item $SS_{Time}$
  \item $SS_{within}$
  \item $SS_{Subject}$
  \item $SS_{error}$
  \end{itemize}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Example}\scriptsize
\begin{verbatim}
> xx
  subject t1 t2 t3
1       1 45 50 55
2       2 42 42 45
3       3 36 41 43
4       4 39 35 40
5       5 51 55 59
6       6 44 49 56
> n <- 6
> k <- 3
> require(reshape2)
> xx <- melt(xx,id.vars = "subject")  
> ## Sum of Squares time
> (tmp <- aggregate(value ~ variable,FUN = "mean",data=xx))
  variable    value
1       t1 42.83333
2       t2 45.33333
3       t3 49.66667
> (sstime <- sum(6*(tmp$value - mean(xx$value))**2))
[1] 143.4444
> ## sum of squares within
> (xx <- xx %>% group_by(variable) %>% mutate(gr.mean=mean(value)))
Source: local data frame [18 x 4]
Groups: variable

   subject variable value  gr.mean
1        1       t1    45 42.83333
2        2       t1    42 42.83333
3        3       t1    36 42.83333
4        4       t1    39 42.83333
5        5       t1    51 42.83333
6        6       t1    44 42.83333
7        1       t2    50 45.33333
8        2       t2    42 45.33333
9        3       t2    41 45.33333
10       4       t2    35 45.33333
11       5       t2    55 45.33333
12       6       t2    49 45.33333
13       1       t3    55 49.66667
14       2       t3    45 49.66667
15       3       t3    43 49.66667
16       4       t3    40 49.66667
17       5       t3    59 49.66667
18       6       t3    56 49.66667
> (ssw <- sum((xx$value - xx$gr.mean)**2))
[1] 715.5
> ## sum of squares sub
> (sub.xx <- xx %>% group_by(subject) %>% summarise(sub.mean=mean(value)))
Source: local data frame [6 x 2]

  subject sub.mean
1       1 50.00000
2       2 43.00000
3       3 40.00000
4       4 38.00000
5       5 55.00000
6       6 49.66667
> (sssub <- k*sum((sub.xx$sub.mean - mean(xx$value))**2))
[1] 658.2778
> ## sum of squares error
> (sserror <- ssw - sssub)
[1] 57.22222
> ## ssw
\end{verbatim}
\end{frame}


\begin{frame}[fragile, allowframebreaks]\frametitle{Example}
  \begin{itemize}
  \item now it is ease to calculate the meas squares and the F statistic
  \end{itemize}\scriptsize
\begin{verbatim}
> ## mean squares
> (mstime <- sstime/(k-1))
[1] 71.72222
> (mserror <- sserror/((n-1)*(k-1)))
[1] 5.722222
> (F <- mstime/mserror)
[1] 12.53398
> pf(F,k-1,((n-1)*(k-1)))
[1] 0.9981144
> 1-pf(F,k-1,((n-1)*(k-1)))
[1] 0.001885591
\end{verbatim}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Example}\scriptsize
\begin{verbatim}
> require(ez)
> xx <- as.data.frame(xx)
> (an <- ezANOVA(data=xx,dv = value,wid= subject, within = variable))
Warnung: Converting "subject" to factor for ANOVA.
$ANOVA
    Effect DFn DFd        F           p p<.05       ges
2 variable   2  10 12.53398 0.001885591     * 0.1670008

$`Mauchly's Test for Sphericity`
    Effect         W         p p<.05
2 variable 0.4335338 0.1879515      

$`Sphericity Corrections`
    Effect       GGe       p[GG] p[GG]<.05      HFe       p[HF] p[HF]<.05
2 variable 0.6383796 0.008985215         * 0.760165 0.005284458         *
\end{verbatim}
\end{frame}


\section{Multivariate Analysis of Variance}
\begin{frame}\frametitle{MANOVA}
  \begin{itemize}
  \item in general, the framework of multivariate linear models extends quite elegantly to repeated-measure design
  \item the $p$ responses per individual related to the dependend variables in the model
  \item the treatment sum of squares and the error sum of squares from the univariate case last week extends to the $p \times p$ sum of squares and crossproducts
$$ \mathbb{H}\equiv \mathbb{SSP_{H}}$$ and $$ \mathbb{E}\equiv \mathbb{SSP_{E}}$$
  \item test statistics (Wilks $\Lambda$, Pillai trace, Hotelling-Lawley trace, Roys maximum root) for testing are based on the non-zero latent roots of $\mathbb{HE}^{-1}$ and attempt to capture how large $\mathbb{H}$ relative to $\mathbb{E}$
  \item all these statistics have transformations to F 
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{MANOVA}
  \begin{itemize}
  \item the matrix $\mathbb{H}$ has the form
    \begin{displaymath}
      \mathbb{H} = \begin{pmatrix} 
        \mathrm{SSH}_{11} & \mathrm{SPH}_{12} & \cdots & \mathrm{SPH}_{1p} \\    
        \mathrm{SPH}_{12} & \mathrm{SSH}_{22} & \cdots & \mathrm{SPH}_{2p} \\    
        \vdots & \vdots & \ddots & \vdots \\    
        \mathrm{SPH}_{1p} & \mathrm{SPH}_{2p} & \cdots & \mathrm{SSH}_{pp} \\    
      \end{pmatrix}
    \end{displaymath}
  \item where e.g. $\mathrm{SSH}_{22} = n \sum_{i=1}^k (\bar{y}_{i.2} - \bar{y}_{..2})^2$
  \item and e.g. $\mathrm{SPH}_{12} = n \sum_{i=1}^k (\bar{y}_{i.1} - \bar{y}_{..1})(\bar{y}_{i.2} - \bar{y}_{..2})$
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{MANOVA}
  \begin{itemize}
  \item the matrix $\mathbb{E}$ has the form
    \begin{displaymath}
      \mathbb{H} = \begin{pmatrix} 
        \mathrm{SSE}_{11} & \mathrm{SPE}_{12} & \cdots & \mathrm{SPE}_{1p} \\    
        \mathrm{SPE}_{12} & \mathrm{SSE}_{22} & \cdots & \mathrm{SPE}_{2p} \\    
        \vdots & \vdots & \ddots & \vdots \\    
        \mathrm{SPE}_{1p} & \mathrm{SPE}_{2p} & \cdots & \mathrm{SSE}_{pp} \\    
      \end{pmatrix}
    \end{displaymath}
  \item where e.g. $\mathrm{SSE}_{22} =  \sum_{i=1}^k \sum_{j=1}^n (y_{ij2} - \bar{y}_{i.2})^2$
  \item and e.g. $\mathrm{SPE}_{12} = n \sum_{i=1}^k \sum_{j=1}^n (y_{ij1} - \bar{y}_{i.1})(y_{ij2} - \bar{y}_{i.2})$
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{Example Data}
  \begin{itemize}
  \item weights of guinea pigs under three levels of vitamin E supplements
  \item measured six times at the end of week 1, 3, 4, 5, 6, and 7
  \item contained in guinea.rdata
  \item Crowder and Hand 1990
  \end{itemize}
\end{frame}


\begin{frame}[fragile]\frametitle{Example Data}
  \begin{itemize}
  \item load the data print them on the screen \scriptsize
\begin{verbatim}
> load("guinea.rdata")
> head(guinea,10)
   Dose Animal  X1  X3  X4  X5  X6  X7
1     0      1 455 460 510 504 436 466
2     0      2 467 565 610 596 542 587
3     0      3 445 530 580 597 582 619
4     0      4 485 542 594 583 611 612
5     0      5 480 500 550 528 562 576
6     1      6 514 560 565 524 552 597
7     1      7 440 480 536 484 567 569
8     1      8 495 570 569 585 576 677
9     1      9 520 590 610 637 671 702
10    1     10 503 555 591 605 649 675
\end{verbatim}
  \end{itemize}
\end{frame}


\begin{frame}[fragile]\frametitle{Example Data}
  \begin{itemize}
  \item reshape the data for ggplot2
  \item plot boxplots and means per treatment group \scriptsize
\begin{verbatim}
> require(reshape2)
> dl <- melt(guinea,id.vars = c("Dose","Animal"))
> dl$variable <- extract_numeric(dl$variable)
> dl$group <- factor(dl$Dose)
> head(dl)
  Dose Animal variable value group
1    0      1        1   455     0
2    0      2        1   467     0
3    0      3        1   445     0
4    0      4        1   485     0
5    0      5        1   480     0
6    1      6        1   514     1
\end{verbatim}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]\frametitle{Example Data}
\scriptsize
\begin{verbatim}
> ggplot(dl,aes(x=variable,y=value,colour=group)) +
+     geom_boxplot(aes(x=variable,group=factor(variable))) +
+     stat_summary(fun.y="mean",geom = "line") 
\end{verbatim}
  \begin{center}
    \includegraphics[width=11cm, height=7cm]{rma1.png}
  \end{center}
\end{frame}

\begin{frame}\frametitle{Basic multivariate model}
  \begin{itemize}
  \item design
  \end{itemize}
  \begin{center}
    \begin{tabular}{c c c c c c c}
      & & \multicolumn{5}{c}{Factor A (Repeated Measures)} \\ \hline
      & Subjects & $A_1$ & $A_2$ & $\cdots$ & $A_p$ & \\
      & $S_{1}$ & $( y_{11}$ & $y_{12}$ & $\cdots$ & $y_{1p} )$ & = $\mathbf{y^t_{1}}$ \\
      & $S_{2}$ & $( y_{21}$ & $y_{22}$ & $\cdots$ & $y_{2p} )$ & = $\mathbf{y^t_{2}}$ \\
      & $S_{3}$ & $( y_{31}$ & $y_{32}$ & $\cdots$ & $y_{3p} )$ & = $\mathbf{y^t_{3}}$ \\
      & $\vdots$ & $\vdots$ & $\vdots$ &  & $ \vdots$ o& $ \vdots $ \\
      & $S_{n}$ & $( y_{n1}$ & $y_{n2}$ & $\cdots$ & $y_{np} )$ & = $\mathbf{y^t_{n}}$ \\
    \end{tabular}
  \end{center}
\end{frame}


\begin{frame}[fragile]\frametitle{Basic multivariate model}
  \begin{itemize}
  \item basic MVLM with an intercept only
  \item intercepts estimate the means at each instant of time
  \end{itemize}\scriptsize
\begin{verbatim}
> ## model
> guinea$Dosef <- factor(guinea$Dose)
> ### Basic multivariate linear model
> mod <- lm(cbind(X1,X3,X4,X5,X6,X7) ~ 1,data=guinea)
> (mod <- lm(cbind(X1,X3,X4,X5,X6,X7) ~ 1,data=guinea))

Call:
lm(formula = cbind(X1, X3, X4, X5, X6, X7) ~ 1, data = guinea)

Coefficients:
             X1     X3     X4     X5     X6     X7   
(Intercept)  486.2  535.0  574.3  566.8  579.3  613.1
\end{verbatim}
\end{frame}


\begin{frame}[fragile]\frametitle{Basic multivariate model}
  \begin{itemize}
  \item now test the Null hypothesis $$\mu_1=\mu_2=\ldots =\mu_n$$
  \item it is the simplest case of a multivariate test
  \end{itemize}\scriptsize
\begin{verbatim}
> (av <- Anova(mod))
Note: model has only an intercept; equivalent type-III tests substituted.

Type III MANOVA Tests: Pillai test statistic
            Df test stat approx F num Df den Df    Pr(>F)    
(Intercept)  1   0.99888   1341.3      6      9 9.286e-13 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
\end{verbatim}
\end{frame}

\begin{frame}[fragile]\frametitle{Extract $\mathbb{H}$}
  \begin{itemize}
  \item extract the sum of squares and products matrix a) for hypothesis
  \end{itemize}\scriptsize
\begin{verbatim}
> av$SSP
$`(Intercept)`
        X1      X3      X4      X5      X6      X7
X1 3545857 3901755 4188127 4133672 4224592 4471095
X3 3901755 4293375 4608490 4548570 4648615 4919860
X4 4188127 4608490 4946733 4882415 4989803 5280956
X5 4133672 4548570 4882415 4818934 4924925 5212293
X6 4224592 4648615 4989803 4924925 5033248 5326936
X7 4471095 4919860 5280956 5212293 5326936 5637761  
\end{verbatim}
\end{frame}


\begin{frame}[fragile]\frametitle{Extract $\mathbb{E}$}
  \begin{itemize}
  \item extract the sum of squares and products matrix b) for errors
  \end{itemize}\scriptsize
\begin{verbatim}
> av$SSPE
        X1    X3       X4      X5       X6       X7
X1 11450.4 10716  5679.20  9326.6 13435.20 14389.80
X3 10716.0 19668 13703.00 19888.0 21463.00 25693.00
X4  5679.2 13703 13294.93 17357.8 18419.93 19089.73
X5  9326.6 19888 17357.80 29166.4 27322.80 29977.20
X6 13435.2 21463 18419.93 27322.8 45448.93 42336.73
X7 14389.8 25693 19089.73 29977.2 42336.73 47268.93
\end{verbatim}
\end{frame}


%% \begin{frame}[fragile]\frametitle{HE plot}
%%   \begin{itemize}
%%   \item  size of the (degenerate) ellipse for the intercept term relative to that for Error gives the strength of evidence for the difference between the sample means and the means under
%%   \item the $\mathbb{H}$ ellipse extends outside the $\mathbb{E}$ ellipse (anywhere), this signals that $H_0$ is clearly rejected (for some linear combination of the response variables)
%%   \end{itemize}
%%   \begin{center}
%%     \includegraphics[height=5cm]{rma2.png}
%%   \end{center}
%% \end{frame}

\begin{frame}[fragile]\frametitle{Testing within-S effects}
  \begin{itemize}
  \item but up to now there is no information about the within effect structure
  \item for repeated measurement design we need to specify the intra-subject design
  \item structure  for  within-S  effects is specified through the arguments \texttt{idata} and \texttt{idesign}
  \item we need to contruct a time variable for the different measurement times
  \end{itemize}\scriptsize
\begin{verbatim}
> idata <- data.frame(time=factor(c(1,3:7)))
> (av2 <- Anova(mod, idata = idata, idesign = ~time))
Note: model has only an intercept; equivalent type-III tests substituted.

Type III Repeated Measures MANOVA Tests: Pillai test statistic
            Df test stat approx F num Df den Df    Pr(>F)    
(Intercept)  1   0.99561   3176.8      1     14 < 2.2e-16 ***
time         1   0.95566     43.1      5     10 1.899e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  
\end{verbatim}
\end{frame}


\begin{frame}[fragile]\frametitle{Test Statistics}
  \begin{itemize}
  \item using the Wilks Statistic instead of the default (Pillai)
  \end{itemize}\scriptsize
\begin{verbatim}
  > (av2 <- Anova(mod, test="Wilks", idata = idata, idesign = ~time))
  Note: model has only an intercept; equivalent type-III tests substituted.

  Type III Repeated Measures MANOVA Tests: Wilks test statistic
  Df test stat approx F num Df den Df    Pr(>F)    
  (Intercept)  1  0.004388   3176.8      1     14 < 2.2e-16 ***
  time         1  0.044335     43.1      5     10 1.899e-06 ***
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
\end{verbatim}
\end{frame}


\begin{frame}[fragile]\frametitle{The 4 Test Statistics}
  \begin{itemize}
  \item extract all test statistics
  \end{itemize}\scriptsize
\begin{verbatim}
> source("functions.r")
> get.p.vals.all(av2)
                   Df    test stat  approx F num Df den Df       Pr(>F)
(Intercept) Pillai  1 9.956124e-01 3176.8006      1     14 6.569937e-18
(Intercept) Wilks   1 4.387614e-03 3176.8006      1     14 6.569937e-18
(Intercept) HL      1 2.269143e+02 3176.8006      1     14 6.569937e-18
(Intercept) Roy     1 2.269143e+02 3176.8006      1     14 6.569937e-18
time Pillai         1 9.556647e-01   43.1108      5     10 1.899089e-06
time Wilks          1 4.433528e-02   43.1108      5     10 1.899089e-06
time HL             1 2.155540e+01   43.1108      5     10 1.899089e-06
time Roy            1 2.155540e+01   43.1108      5     10 1.899089e-06
\end{verbatim}
\end{frame}


\begin{frame}[fragile, allowframebreaks]\frametitle{The 4 Test Statistics}
  \begin{itemize}
  \item when $H_0$ is true (i.e. $\mathbf{\mu_1} = \mathbf{\mu_1} = \ldots =  \mathbf{\mu_k}$) all four MANOVA test statistics have the same type I error rate
  \item when $H_0$ is false, the four tests have different probabilities of rejection
  \item relative powers of the four tests depend on the configuration of the mean vectors in the $s$-dimensional space, where $s=\min(p,\nu_H)$
  \item indication about this configuration is given by the eigenvalues of $\mathbb{E}^{-1}\mathbb{H}$
  \end{itemize}\scriptsize
\end{frame}

\begin{frame}[fragile]\frametitle{The 4 Test Statistics}\scriptsize
\begin{verbatim}
> source("functions.r")
> get.p.vals.all(av2)
                   Df    test stat  approx F num Df den Df       Pr(>F)
(Intercept) Pillai  1 9.956124e-01 3176.8006      1     14 6.569937e-18
(Intercept) Wilks   1 4.387614e-03 3176.8006      1     14 6.569937e-18
(Intercept) HL      1 2.269143e+02 3176.8006      1     14 6.569937e-18
(Intercept) Roy     1 2.269143e+02 3176.8006      1     14 6.569937e-18
time Pillai         1 9.556647e-01   43.1108      5     10 1.899089e-06
time Wilks          1 4.433528e-02   43.1108      5     10 1.899089e-06
time HL             1 2.155540e+01   43.1108      5     10 1.899089e-06
time Roy            1 2.155540e+01   43.1108      5     10 1.899089e-06
\end{verbatim}
\end{frame}


\begin{frame}[fragile,allowframebreaks]\frametitle{The 4 Test Statistics}
    \begin{itemize}
    \item if one eigenvalue is large and the others are small (collinear mean vectors) Roy is the most powerful (in terms of power: Roy > LH > Wilk > Pillai)
    \item intermediate between collinear and diffuse: Pillai > Wilk > LH > Roy
    \item Pillai, Wilk, LH are robust against skewness
    \item Pillai is better in presence of heterogeneity of covariance matrices
    \item Pillai in most cases the best choice (but performs not well in case of collinearity)
    \item Wilks not far behind but more sensible in case of severe heterogeneity of covariance matrices
    \item nowadays software programs calculate all of them and most of the times they lead to the same conclusions, in case of conflicting conclusions examination of eigenvalues and covariance matrices is recommended
    \end{itemize}
\end{frame}

\begin{frame}[fragile]\frametitle{The 4 Test Statistics}
  \begin{itemize}
  \item calculate the eigenvalues
  \end{itemize}\scriptsize
\begin{verbatim}
> Re(eigen(solve(av$SSPE) %*% av$SSP[[1]])$values)
[1]  8.941938e+02 -7.835860e-14 -7.835860e-14  2.256895e-13  2.256895e-13
[6]  1.929296e-14
> Re(eigen(solve(av2.mod2$SSPE$time) %*% av2.mod2$SSP$time)$values)
[1]  2.476092e+01 -7.105427e-15 -1.958341e-15 -1.958341e-15  2.272995e-17
\end{verbatim}
\end{frame}


\begin{frame}[fragile]\frametitle{Add between-S effects}
  \begin{itemize}
  \item now add the group term to the model (Dosef)
  \item design:
  \end{itemize}\scriptsize
\end{frame}

\begin{frame}[fragile]\frametitle{Add between-S effects}
  \begin{itemize}
  \item design:
  \end{itemize}\scriptsize
  \begin{center}
    \begin{tabular}{c c c c c c c}
      & & \multicolumn{5}{c}{Factor A (Repeated Measures)} \\ \hline
Factor B & Subjects & $A_1$ & $A_2$ & $\cdots$ & $A_p$ & \\
$B_1$ & $S_{11}$ & $( y_{111}$ & $y_{112}$ & $\cdots$ & $y_{11p} )$ & = $\mathbf{y^t_{11}}$ \\
      & $S_{12}$ & $( y_{121}$ & $y_{122}$ & $\cdots$ & $y_{12p} )$ & = $\mathbf{y^t_{12}}$ \\
      & $S_{13}$ & $( y_{131}$ & $y_{132}$ & $\cdots$ & $y_{13p} )$ & = $\mathbf{y^t_{13}}$ \\
      & $\vdots$ & $\vdots$ & $\vdots$ &  & $ \vdots$ & $ \vdots $ \\
      & $S_{1n}$ & $( y_{2n1}$ & $y_{2n2}$ & $\cdots$ & $y_{2np} )$ & = $\mathbf{y^t_{2n}}$ \\
$B_2$ & $S_{21}$ & $( y_{211}$ & $y_{212}$ & $\cdots$ & $y_{21p} )$ & = $\mathbf{y^t_{21}}$ \\
      & $S_{22}$ & $( y_{221}$ & $y_{222}$ & $\cdots$ & $y_{22p} )$ & = $\mathbf{y^t_{22}}$ \\
      & $S_{23}$ & $( y_{231}$ & $y_{232}$ & $\cdots$ & $y_{23p} )$ & = $\mathbf{y^t_{23}}$ \\
      & $\vdots$ & $\vdots$ & $\vdots$ &  & $ \vdots$ o& $ \vdots $ \\
      & $S_{2n}$ & $( y_{2n1}$ & $y_{2n2}$ & $\cdots$ & $y_{2np} )$ & = $\mathbf{y^t_{2n}}$ \\
$\vdots$  & $\vdots$ & $\vdots$ & $\vdots$ &  & $ \vdots$ & $ \vdots $ \\
$B_k$ & $S_{k1}$ & $( y_{k11}$ & $y_{k12}$ & $\cdots$ & $y_{k1p} )$ & = $\mathbf{y^t_{k1}}$ \\
      & $S_{k2}$ & $( y_{k21}$ & $y_{k22}$ & $\cdots$ & $y_{k2p} )$ & = $\mathbf{y^t_{k2}}$ \\
      & $S_{k3}$ & $( y_{k31}$ & $y_{k32}$ & $\cdots$ & $y_{k3p} )$ & = $\mathbf{y^t_{k3}}$ \\
      & $\vdots$ & $\vdots$ & $\vdots$ &  & $ \vdots$ & $ \vdots $ \\
      & $S_{kn}$ & $( y_{kn1}$ & $y_{kn2}$ & $\cdots$ & $y_{knp} )$ & = $\mathbf{y^t_{kn}}$ \\
    \end{tabular}
  \end{center}
\end{frame}


\begin{frame}[fragile,allowframebreaks]\frametitle{Add between-S effects}\scriptsize
\begin{verbatim}
> (mod2 <- lm(cbind(X1,X3,X4,X5,X6,X7) ~ Dosef,data=guinea))

Call:
lm(formula = cbind(X1, X3, X4, X5, X6, X7) ~ Dosef, data = guinea)

Coefficients:
             X1     X3     X4     X5     X6     X7   
(Intercept)  466.4  519.4  568.8  561.6  546.6  572.0
Dosef1        28.0   31.6    5.4    5.4   56.4   72.0
Dosef2        31.4   15.2   11.0   10.2   41.6   51.2

> idata <- data.frame(time)
> (av2.mod2 <- Anova(mod2, idata = idata, idesign = ~time))

Type II Repeated Measures MANOVA Tests: Pillai test statistic
            Df test stat approx F num Df den Df    Pr(>F)    
(Intercept)  1   0.99627   3202.0      1     12 6.121e-16 ***
Dosef        2   0.14960      1.1      2     12   0.37821    
time         1   0.96118     39.6      5      8 1.954e-05 ***
Dosef:time   2   1.07059      2.1     10     18   0.08557 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
\end{verbatim}
\end{frame}

\begin{frame}[fragile]\frametitle{MANOVA Tests}\scriptsize
\begin{verbatim}
> get.p.vals.all(av2.mod2)
                   Df    test stat    approx F num Df den Df       Pr(>F)
(Intercept) Pillai  1 9.962663e-01 3201.999302      1     12 6.120979e-16
(Intercept) Wilks   1 3.733666e-03 3201.999302      1     12 6.120979e-16
(Intercept) HL      1 2.668333e+02 3201.999302      1     12 6.120979e-16
(Intercept) Roy     1 2.668333e+02 3201.999302      1     12 6.120979e-16
Dosef Pillai        2 1.496026e-01    1.055525      2     12 3.782088e-01
Dosef Wilks         2 8.503974e-01    1.055525      2     12 3.782088e-01
Dosef HL            2 1.759208e-01    1.055525      2     12 3.782088e-01
Dosef Roy           2 1.759208e-01    1.055525      2     12 3.782088e-01
time Pillai         1 9.611815e-01   39.617478      5      8 1.954259e-05
time Wilks          1 3.881848e-02   39.617478      5      8 1.954259e-05
time HL             1 2.476092e+01   39.617478      5      8 1.954259e-05
time Roy            1 2.476092e+01   39.617478      5      8 1.954259e-05
Dosef:time Pillai   2 1.070585e+00    2.073405     10     18 8.556610e-02
Dosef:time Wilks    2 1.790515e-01    2.181212     10     16 7.931593e-02
Dosef:time HL       2 3.190768e+00    2.233537     10     14 8.241562e-02
Dosef:time Roy      2 2.668246e+00    4.802843      5      9 2.045621e-02  

\end{verbatim}

\end{frame}


\begin{frame}[allowframebreaks]\frametitle{Assumptions MANOVA}
  \begin{itemize}
  \item Normal Distribution: The dependent variable should be normally distributed within groups.  Overall, the F test is robust to non-normality, if the non-normality is caused by skewness rather than by outliers.
  \item Linearity: MANOVA assumes that there are linear relationships among all pairs of dependent variables, all pairs of covariates, and all dependent variable-covariate pairs in each cell.  Therefore, when the relationship deviates from linearity, the power of the analysis will be compromised.
  \item Remember that the error variance is computed (SS error) by adding up the sums of squares within each group. If the variances in the two groups are different from each other, then adding the two together is not appropriate, and will not yield an estimate of the common within-group variance.  Homoscedasticity can be examined graphically or by means of a number of statistical tests.
  \item Homogeneity of Variances and Covariances: In multivariate designs, with multiple dependent measures, the homogeneity of variances assumption described earlier also applies. However, since there are multiple dependent variables, it is also required that their intercorrelations (covariances) are homogeneous across the cells of the design. There are various specific tests of this assumption.
  \item Outliers: Like ANOVA, MANOVA is extremely sensitive to outliers.  Outliers may produce either a Type I or Type II error and give no indication as to which type of error is occurring in the analysis.  There are several programs available to test for univariate and multivariate outliers.
  \item Multicollinearity and Singularity: When there is high correlation between dependent variables, one dependent variable becomes a near-linear combination of the other dependent variables.  Under such circumstances, it would become statistically redundant and suspect to include both combinations.
  \end{itemize}
\end{frame}



\section{Mixed or Multilevel Models}
\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}
  \begin{itemize}
  \item the mixed model looks very similar to ANOVA: $$Y_{ij} = \mu + \alpha_j + S_i + Error_{ij}$$
  \item the difference is the assumption:
    \begin{itemize}
    \item $\mu$ is a fixed effect: no estimate of variability
    \item $\alpha_j$ are also fixed effects: no estimate of variability
    \item $S_i$ are random effects have normal distribution with zero mean
    \item $E_{ij}$ are normally distributed with mean zero (as usual)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}
  \begin{itemize}
  \item this also can be written as follows:
    \begin{itemize}
    \item $Y_{ij} = [\pi_{0i} + \pi_{2i} \cdot \mathrm{TIME}_{ij}] + [\epsilon_{ij}]$ (structural part + stochastic part)
    \item $Y_{ij}$ is the value of subject $i$ at time $j$ as a linear function of $\mathrm{TIME}$
    \item $\pi_{0i}$ and $\pi_{2i}$ are individual parameters that characterize its shape for the $i$th subject and where 
      $$\pi_{0i} = \gamma_{00} + \gamma_{01}\mathrm{X}_i + \xi_{0i}$$ and
      $$\pi_{1i} = \gamma_{10} + \gamma_{11}\mathrm{X}_i + \xi_{1i}$$ where
    \item $\gamma_{00}$ and $\gamma_{10}$ the level-2 intercepts, represent the population average initial status and rate of change where $\mathrm{X}=0$ 
    \item the level-2 slopes $\gamma_{01}$ and $\gamma_{11}$ represent the treatment effect $\mathrm{X}$ on the intercept and the slope respectively
    \item $\xi_{0i}$ and $\xi_{1i}$, the level-2 residuals represent those portions of initial status or rate of change that are unexplained at level-2, they represent deviations of the individual change trajectories around their respective group average trends
    \item $\xi_{0i}$ and $\xi_{1i}$ are assumed to be independently draw from a bivariate normal distribution with mean 0 and variances $\sigma_0^2$ and $\sigma_1^2$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}\scriptsize
\begin{verbatim}
> dl$variable <- factor(dl$variable)
> require(nlme)
> Lme.mod <- lme(value ~ group * variable, random = ~ 1 | Animal, data = dl)
> anova(Lme.mod)
               numDF denDF  F-value p-value
(Intercept)        1    60 3201.999  <.0001
group              2    12    1.056  0.3782
variable           5    60   52.550  <.0001
group:variable    10    60    1.799  0.0801
\end{verbatim}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}
  \scriptsize
\begin{verbatim}
> require(lme4)
> Lme.mod <- lmer(value ~ group * variable + (1 | Animal), data = dl)
> anova(Lme.mod)
Analysis of Variance Table
               Df Sum Sq Mean Sq F value
group           2   1145   572.7  1.0555
variable        5 142554 28510.9 52.5505
group:variable 10   9763   976.3  1.7994
> fixed.effects(Lme.mod)
     (Intercept)           group1           group2        variable3 
           466.4             28.0             31.4             53.0 
       variable4        variable5        variable6        variable7 
           102.4             95.2             80.2            105.6 
group1:variable3 group2:variable3 group1:variable4 group2:variable4 
             3.6            -16.2            -22.6            -20.4 
group1:variable5 group2:variable5 group1:variable6 group2:variable6 
           -22.6            -21.2             28.4             10.2 
group1:variable7 group2:variable7 
            44.0             19.8 
\end{verbatim}
\end{frame}


\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}
  \begin{itemize}
  \item extract fixed effects
  \end{itemize}
  \scriptsize
\begin{verbatim}
> fixed.effects(Lme.mod)
     (Intercept)           group1           group2        variable3 
           466.4             28.0             31.4             53.0 
       variable4        variable5        variable6        variable7 
           102.4             95.2             80.2            105.6 
group1:variable3 group2:variable3 group1:variable4 group2:variable4 
             3.6            -16.2            -22.6            -20.4 
group1:variable5 group2:variable5 group1:variable6 group2:variable6 
           -22.6            -21.2             28.4             10.2 
group1:variable7 group2:variable7 
            44.0             19.8 
\end{verbatim}
\end{frame}

\begin{frame}[fragile, allowframebreaks]\frametitle{Alternative Approach - Mixed Model}
  \begin{itemize}
  \item post hoc test
  \end{itemize}
  \scriptsize
\begin{verbatim}
> summary(glht(Lme.mod, linfct=mcp(group="Tukey")))

	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = value ~ group * variable + (1 | Animal), data = dl)

Linear Hypotheses:
           Estimate Std. Error z value Pr(>|z|)
1 - 0 == 0    28.00      27.69   1.011    0.570
2 - 0 == 0    31.40      27.69   1.134    0.493
2 - 1 == 0     3.40      27.69   0.123    0.992
(Adjusted p values reported -- single-step method)

Warnmeldung:
In mcp2matrix(model, linfct = linfct) :
  covariate interactions found -- default contrast might be inappropriate
\end{verbatim}
\end{frame}

\begin{frame}[fragile,allowframebreaks]\frametitle{Mixed Models}
  \begin{itemize}
  \item average the interaction term
  \end{itemize}
\scriptsize
\begin{verbatim}
> ## consider interaction terms
> summary(glht(Lme.mod, linfct=mcp(group="Tukey",interaction_average = TRUE)))

	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = value ~ group * variable + (1 | Animal), data = dl)

Linear Hypotheses:
           Estimate Std. Error z value Pr(>|z|)
1 - 0 == 0   33.133     24.202   1.369    0.357
2 - 0 == 0   26.767     24.202   1.106    0.510
2 - 1 == 0   -6.367     24.202  -0.263    0.963
(Adjusted p values reported -- single-step method)
\end{verbatim}
\end{frame}


\begin{frame}[fragile,allowframebreaks]\frametitle{Mixed Models}
\scriptsize
\begin{verbatim}
  > Lme.mod <- lmer(value ~ group + variable + (1 | Animal), data = dl)
  > anova(Lme.mod)
  Analysis of Variance Table
  Df Sum Sq Mean Sq F value
  group     2   1276   638.1  1.0555
  variable  5 142555 28510.9 47.1641
  > summary(glht(Lme.mod, linfct=mcp(group="Tukey")))

  Simultaneous Tests for General Linear Hypotheses

  Multiple Comparisons of Means: Tukey Contrasts


  Fit: lmer(formula = value ~ group + variable + (1 | Animal), data = dl)

  Linear Hypotheses:
  Estimate Std. Error z value Pr(>|z|)
  1 - 0 == 0   33.133     24.202   1.369    0.357
  2 - 0 == 0   26.767     24.202   1.106    0.510
  2 - 1 == 0   -6.367     24.202  -0.263    0.963
  (Adjusted p values reported -- single-step method)
\end{verbatim}
\end{frame}



\begin{frame}\frametitle{Exercises}
  \begin{enumerate}
  \item try to set up an unconditional means model using lme or lmer from the respective package.
  \item Extract the coefficients using \texttt{coef()} and interpret the results.
  \item add time as fixed effect.
  \item add time as random effect. Again: extract the coefficients, interpret.
  \item add the group variable as factor, do an posthoc test
  \end{enumerate}
\end{frame}


\begin{frame}[allowframebreaks, fragile]\frametitle{Solutions}
  \begin{enumerate}
  \item try to set up an unconditional means model using lme or lmer from the respective package.\scriptsize
\begin{verbatim}
> mod.0 <- lmer(value ~ 1 + (1 | Animal ), data = dl)

\end{verbatim}
\normalsize
  \item Extract the coefficients using \texttt{coef()} and interpret the results.\scriptsize
\begin{verbatim}
> coef(mod.0)
$Animal
   (Intercept)
1     496.1230
2     560.5914
3     558.9076
4     567.8080
5     540.0241
6     553.9762
7     525.5909
8     573.2205
9     604.2520
10    585.9699
11    588.8565
12    559.8698
13    551.5707
14    585.3685
15    534.3711

attr(,"class")
[1] "coef.mer"  
  
\end{verbatim}
\normalsize
  \item add time as fixed effect.\scriptsize
\begin{verbatim}
> mod.1 <- lmer(value ~ variable + (1 | Animal ), data = dl)
> coef(mod.1)
$Animal
   (Intercept) variable
1     394.8259 19.40286
2     476.9201 19.40286
3     474.7759 19.40286
4     486.1098 19.40286
5     450.7296 19.40286
6     468.4963 19.40286
7     432.3503 19.40286
8     493.0020 19.40286
9     532.5175 19.40286
10    509.2371 19.40286
11    512.9129 19.40286
12    476.0012 19.40286
13    465.4331 19.40286
14    508.4713 19.40286
15    443.5311 19.40286
\end{verbatim}
\normalsize
  \item add time as random effect. Again: extract the coefficients, interpret.\scriptsize
\begin{verbatim}
> mod.2 <- lmer(value ~ variable + (1 + variable | Animal ), data = dl)
> coef(mod.2)
$Animal
   (Intercept)  variable
1     452.6571  4.989677
2     475.9532 19.079395
3     474.2833 20.463988
4     478.1603 21.318140
5     468.0379 15.382203
6     473.9412 17.008690
7     462.0846 13.445867
8     480.0258 22.650268
9     491.3526 29.244908
10    484.4619 25.718884
11    485.6489 26.112158
12    475.6310 19.023129
13    472.0510 18.168807
14    485.1363 24.115063
15    465.8891 14.321680

attr(,"class")
[1] "coef.mer"  
\end{verbatim}
\normalsize
  \item add the group variable as factor, do an posthoc test\scriptsize
\begin{verbatim}
> mod.3 <- lmer(value ~ variable + group + (1 + variable | Animal ), data = dl)
> coef(mod.3)
$Animal
   (Intercept) variable   group1   group2
1     448.2977  5.81501 10.60605 14.33476
2     472.9694 19.59789 10.60605 14.33476
3     465.2712 22.15993 10.60605 14.33476
4     473.0687 22.24370 10.60605 14.33476
5     461.8873 16.53096 10.60605 14.33476
6     469.0268 15.91834 10.60605 14.33476
7     447.5350 14.25275 10.60605 14.33476
8     470.6132 22.42630 10.60605 14.33476
9     483.2428 28.74823 10.60605 14.33476
10    474.3565 25.62254 10.60605 14.33476
11    475.0372 25.41345 10.60605 14.33476
12    466.9784 17.95933 10.60605 14.33476
13    459.9408 17.78472 10.60605 14.33476
14    478.6720 22.60904 10.60605 14.33476
15    453.7132 13.96066 10.60605 14.33476

attr(,"class")
[1] "coef.mer"
> summary(glht(mod.3, linfct=mcp(group="Tukey")))

	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = value ~ variable + group + (1 + variable | Animal), 
    data = dl)

Linear Hypotheses:
           Estimate Std. Error z value Pr(>|z|)
1 - 0 == 0   10.606     16.669   0.636    0.800
2 - 0 == 0   14.335     16.669   0.860    0.666
2 - 1 == 0    3.729     16.669   0.224    0.973
(Adjusted p values reported -- single-step method)
\end{verbatim}
  \end{enumerate}
\end{frame}
